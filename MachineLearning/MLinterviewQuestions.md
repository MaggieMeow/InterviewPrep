# Machine Learning

I summarised the notes and interview questions from the Udacity Machine Learning Nanodegree course and various online articles. To be honest, my memories of many concepts covered have been blurred by the passage of time. But here’s my attempt to clarify them.

## Interview Questions

What type of problem does the model try to solve?
Is it prone to over-fitting? If so, what can be done about this?
Does the model make any important assumptions about the data? 

When might these be unrealistic? How do we examine the data to test whether these assumptions are satisfied?

Does the model have convergence problems? Does it have a random component or will the same training data always generate the same model? How do we deal with random effects in training?

What types of data (numerical, categorical etc…) can the model handle?

Can the model handle missing data? What could we do if we find missing fields in our data?

How interpretable is the model?

What alternative models might we use for the same type of problem that this one attempts to solve, and how does it compare to those?

Can we update the model without retraining it from the beginning?

How fast is prediction compared to other models? How fast is training compared to other models?

Does the model have any meta-parameters and thus require tuning? 

How do we do this?


What is the EM algorithm? Give a couple of applications

*What is deep learning and what are some of the main* 
*characteristics that distinguish it from traditional machine learning*

- Deep Learning focuses even more narrowly on a subset of ML tools and techniques
-  Deep learning aims to model high level abstractions in very complicated data such as images, videos and texts.
- Data are fed through neural networks, as is the case in machine learning.
- “Normal" neural networks usually have one to two hidden layers and are used for SUPERVISED prediction or classification. e.g. SVMs are typically used for binary classification, but occasionally for other SUPERVISED learning tasks.
Deep learning works because of the architecture of the network AND the optimization routine applied to that architecture. But DNN can be used for unsupervised learning.

- The network is a directed graph, meaning that each hidden unit is connected to many other hidden units below it. So each hidden layer going further into the network is a NON-LINEAR combination of the layers below it, because of all the combining and recombining of the outputs from all the previous units in combination with their activation functions.



What is linear in a generalized linear model?

What is a probabilistic graphical model? 

*What is the difference between Markov networks and Bayesian networks*?
The main weakness of Markov networks is their inability to represent induced and non-transitive dependencies; two independent variables will be directly connected by an edge, merely because some other variable depends on both. As a result, many useful independencies go unrepresented in the network. To overcome this deficiency, Bayesian networks use the richer language of directed graphs, where the directions of the arrows permit us to distinguish genuine dependencies from spurious dependencies induced by hypothetical observations.

Give an example of an application of non-negative matrix factorization

On what type of ensemble technique is a random forest based? 

What particular limitation does it try to address?

What methods for dimensionality reduction do you know and how do they compare with each other?

What are some good ways for performing feature selection that do not involve exhaustive search?

How would you evaluate the quality of the clusters that are generated by a run of K-means?

What tools and environments have you used to train and assess models?

Do you have experience with Spark ML or another platform for building machine learning models using very large datasets?

## Notes

## Deep Learning

**Logistic classifier**: wx+b=ywx+b=y, w is weight, x is input, b is bias.
Logistic regression: A regression model where the dependent variable (DV) is categorical. This article covers the case of a binary dependent variable

**Softmax**: S(yi)=eyi∑jeyjS(yi)=eyi∑jeyj turn scores into probabilities.
Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes. Multi-class classification (as opposed to only binary classification).

- If multiply the scores by 10, the probabilities get close to either 0 or 1.
- If divided by 10, the probabilities get close to uniform.

**Cross-entropy**: D(S,L)=−∑iLilog(Si)D(S,L)=−∑iLilog(Si), S is socre, L is lable.

Multinomial logistic classification:linear model wx+bwx+b -> logit score -> softmax S(y) -> Cross-entropy D(S,L) -> 1-hot labels.

**Loss** = average cross-entropy: 1N∑iD(S(wxi+b),Li)1N∑iD(S(wxi+b),Li).

Minimize traning loss using **gradient descent method**.

**Ordinary gradient descent** is a simple algorithm in which we repeatedly make small steps downward on an error surface defined by a loss function of some parameters.

Input is typically normalized, weights are typically initilized with random values from Gaussian distribution.

**Stochastic gradient descent (SGD**) works according to the same principles as ordinary gradient descent, but proceeds more quickly by estimating the gradient from just a few examples at a time instead of the entire training set.

Two methods to help SGD faster:

- **Momentum**: for SGD, each step we take a very small step in a random direction, but on aggregate, those steps take us toward the minimum of the loss. We can take advantage of the knowledge that we’ve accumulated from previous steps about where we should be headed. A cheap way to do that is to keep a running average of the gradients, and to use that running average instead of the direction of the current batch of the data. M <- 0.9M + ΔαΔα.
- **Learning rate decay**: when replacing gradient descent with SGD, we are going to take smaller, noiser steps towards our objective. It is hard to decide how smaller that step should be. However, it is beneficial to make that step smaller and smaller as you train.


### Convolutional Neural Network

#### Convolutional layer
The primary purpose of Convolution in case of a ConvNet is to extract features from the input image. Convolution preserves the spatial relationship between pixels by learning image features using small squares of input data.

Slide the kernel matrix over the image matrix by n pixels (also called ‘stride’) and for every position, we compute element wise multiplication (between the two matrices) and add the multiplication outputs to get the final integer which forms a single element of the output matrix.

The Convolution operation captures **the local dependancies** in the original image. CNN learns the values of these filters/kernels on its own during the training process (although we still need to specify parameters such as number of filters, filter size, architecture of the network etc. before the training process). The more number of filters we have, the more image features get extracted and the better our network becomes at recognizing patterns in unseen images.

The size of the Feature Map (Convolved Feature) is controlled by three parameters: depth, stride and padding.

#### ReLU
ReLU is an element wise operation (applied per pixel) and replaces all negative pixel values in the feature map by zero. Convolution is a linear operation – element wise matrix multiplication and addition, so we account for non-linearity by introducing a non-linear function like ReLU.


#### Fully connected
A traditional Multi-Layer Perceptron that uses a softmax activation function in the output layer.

“Fully connect” all the hidden units to all the input units.

Adding a fully-connected layer is also a (usually) cheap way of learning non-linear combinations of these features. Most of the features from convolutional and pooling layers may be good for the classification task, but combinations of those features might be even better.

For output layer:
The purpose of the Fully Connected layer is to use these features for classifying the input image into various classes based on the training dataset.

#### Locally connected
Restrict the connections between the hidden units and the input units, allowing each hidden unit to connect to only a small subset of the input units. Specifically, each hidden unit will connect to only a small contiguous region of pixels in the input.

#### Pooling
Spatial Pooling (also called subsampling or downsampling) **reduces the dimensionality of each feature map** but retains the most important information. Spatial Pooling can be of different types: Max, Average, Sum etc. The output from the convolutional and pooling layers represent high-level features of the input image.

Advantages:
- Makes the input representations (feature dimension) smaller and **more manageable**
- reduces the number of parameters and computations in the network, therefore, **controlling overfitting**
- makes the network **invariant to small transformations, distortions and translations** in the input image.
- helps us arrive at an almost **scale invariant representation of our image** (the exact term is “equivariant”). This is very powerful since we can detect objects in an image no matter where they are located .

####  Training using Backpropagation
Use backpropagation to calculate the gradients of the error with respect to all weights in the network and use gradient descent to update all filter values / weights and parameter values to minimize the output error.
The weights are adjusted in proportion to their contribution to the total error.


#### Regularisation

Regularization of an estimator works by trading increased bias for reduced variance. An effective regularizer is one that makes a proﬁtable trade, reducing variance significantly while not overly increasing the bias.

**Dropout** is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.

As a neural network learns, neuron weights settle into their context within the network. Weights of neurons are tuned for specific features providing some specialization. Neighboring neurons become to rely on this specialization, which if taken too far can result in a fragile model too specialized to the training data. This reliant on context for a neuron during training is referred to complex co-adaptations.

#### Flatten
The Flatten layer is a utility layer that flattens an input of shape n * c * h * w to a simple vector output of shape n * (c*h*w), so as to consider each pixel as a separate input feature and facilitate the fully connected layer.

## Reinforcement learning

### Markov Decision Process
The general idea of any Markov Process is that "given the present, future is independent of the past".

## Unsupervised learning

### K Means Clustering
k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.

### Expectation maximisation

The EM algorithm is an efficient iterative procedure to compute the Maximum Likelihood (ML) estimate in the presence of missing or hidden data. In ML estimation, we wish to **estimate the model parameter(s) for which the observed data are the most likely**.

An expectation–maximization (EM) algorithm is an iterative method to find maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between performing an expectation (E) step, which creates **a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters**, and a maximization (M) step, which **computes parameters maximizing the expected log-likelihood found on the E step**. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step.

$z_{ij}$ represents the likelihood element i comes from cluster j. Prop to p(el 1 was produced by cluster j). Pass that clustering info z to maximisation step Maximisation step: Compute means for clusters. if $z_{ij}$ is thought of as a {0,1} variable, it's like assigning elements to clusters. But because they are probabilities, we're soft assigning.
All points have some non-zero probability of being in each cluster.
Makes sense because Gaussians have infinite extent
Properties of EM
Monotonically non-decreasing likelihood
i.e. generally goes in a good direction?
Does not converge (does in practice) (vs K Means does)
Will not diverge (bc working in probability space)
Can get stuck (Local optima problem) -> random restart
Works with any distribution (if E, M solvable). Usualy E (estimation) is harder. E-> probabilistic inference, Bayes stuff. M counting things.

## Supervised Learning

### KNN
### Naive Bayes
### Decision Trees
### Neural Networks
### SVM

## Model Evaluation and Validation

#### Accuracy
Accuracy = (no. of items in a class labelled correctly / all items in that class)

Shortcomings:
Not ideal for skewed cases 
May want to err on side of guessing innocent 
Asymmetries favouring different types of error.

#### F1 Score
F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.

F2 measure, which weighs recall higher than precision (by placing more emphasis on false negatives), and the F0.5 measure, which weighs recall lower than precision (by attenuating the influence of false negatives).

Recall = TP/(TP + FN)
Precision = TP/(TP + FP)

#### Feature transformation
**Principal component analysis (PCA**) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.

Feature transform e.g. PCA fit then PCA transform.
PCA fit on training features
PCA transform on training features
PCA transform on test features (usually after training SVC) -> Represent test data with principle components found in training data.

#### Cross-Validation for Parameter Tuning
**GridSearchCV**
Systematically works through multiple combinations of parameter tunes, cross-validating as it goes to determine which tune gives the best performance.

#### Error 
Two main causes of error: Bias and Variance

**Bias** due to a model being unable to represent the complexity of the underlying data.
Accuracy and Underfitting Bias occurs when a model has enough data but is not complex enough to capture the underlying relationships. As a result, the model consistently and systematically misrepresents the data, leading to low accuracy in prediction. This is known as underfitting.


**Variance** due to a model being overly sensitive to the limited data it has been trained on.
Precision and Overfitting When training a model, we typically use a limited number of samples from a larger population. If we repeatedly train a model with randomly selected subsets of data, we would expect its predictons to be different based on the specific examples given to it. Here variance is a measure of how much the predictions vary for any given test sample.

few features used (if you have access to lots more) -> high bias.
Carefully minimised SSE (sum of squares due to error), used lots of features, tuned parameters -> High variance

#### Ideal learning curve
The ultimate goal for a model is one that has good performance that generalizes well to unseen data. In this case, both the testing and training curves converge at similar values.
The smaller the gap between the training and testing sets, the better our model generalizes.

#### Curse of Dimensionality
As the number of features or dimensions grows, the amount of data we need to generalise accurately grows exponentially.


## Auxiliary

Noise Reduction

gaussian discrimination

edge kernel 
gaussian kernel
average kernel

cross correlation




